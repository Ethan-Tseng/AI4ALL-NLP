{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF on Fake News Challenge\n",
    "\n",
    "Let's get started. First, we have to load the training data. What packages do we need for that? From here on out, replace ___ with the necessary code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jul  2 16:50:39 2019\n",
    "@author: Nobline\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's actually load the training data. What pandas command might you need? Take a look back at previous slides if you need a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training data\n",
    "bodies = pd.read_csv(\"train_bodies.csv\")\n",
    "bodies.index = bodies['Body ID']\n",
    "headlines = pd.read_csv(\"train_stances.csv\")\n",
    "headlines.index = headlines['Body ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once, we have our data, we can start extracting our TFIDF features. But wait! Did you notice something strange about the number of articles in train_bodies.csv and train_stances.csv. If not, open up the two files, and see if you notice anything interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yes, you're right!\n",
    "\n",
    "train_bodies.csv has way more rows/data than train_stances.csv. So, here's what we need to do. We need to pick out the article bodies that correspond to the headlines. Why? Think about the goal of our project here. The ultimate goal is to train our model on the relationship between the TFIDF vector of the body and headline and see how that corresponds to the stance (agree, disagree, discuss, unrelated). So if we're looking at the relationship, do we care about the article bodies that have no headline to compare to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#organize training data - pick our articles bodies that we care about\n",
    "trainBodies = bodies.loc[headlines[\"Body ID\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can start to think about how we're going to extract our TFIDF vectors. What package(s) do we need?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract tfidf vectors of article body and headline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create a function called **tfidf_extractor** that takes two parameters: b (set of article bodies), h (set of headlines). This function will extract the TFIDF vectors and print out the resulting matrices. Take a look at the comments and fill in the appropriate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_extractor(b, h):\n",
    "    #initialize TfidfVectorizer\n",
    "    #create a global varible, bodyTFIDF, where you will story the resulting vectors for the article bodies\n",
    "    #extract features and store them in bodyTFIDF\n",
    "    vect = TfidfVectorizer()\n",
    "    global bodyTFIDF\n",
    "    bodyTFIDF = vect.fit_transform(b)\n",
    "    \n",
    "    #print results\n",
    "    print(\"BODIES\")\n",
    "    print(bodyTFIDF)\n",
    "    \n",
    "    #create a global varible, headlineTFIDF, where you will story the resulting vectors for the headlines\n",
    "    #extract features and store them in headlineTFIDF\n",
    "    global headlineTFIDF\n",
    "    headlineTFIDF = vect.fit_transform(h)\n",
    "    \n",
    "    #print results\n",
    "    print(\"HEADLINES\")\n",
    "    print(headlineTFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAST STEP! We're almost done! Let's call the function we just made on our set of articles bodies and headlines and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main action!\n",
    "tfidf_extractor(trainBodies['articleBody'], headlines['Headline'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
