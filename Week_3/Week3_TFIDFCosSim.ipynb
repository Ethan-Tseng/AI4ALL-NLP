{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the Fake News Challenge\n",
    "\n",
    "Welcome to the third and final week of AI4ALL. Let's get started.\n",
    "\n",
    "Below you will find the code you (hopefully) wrote last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jul  2 16:50:39 2019\n",
    "@author: Nobline\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#load training data\n",
    "bodies = pd.read_csv(\"train_bodies.csv\")\n",
    "headlines = pd.read_csv(\"train_stances.csv\")\n",
    "\n",
    "import re\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean(doc):\n",
    "    for i in range(doc.shape[0]):\n",
    "        #lowercasing\n",
    "        doc.set_value(i, doc.iloc[i].lower())\n",
    "    print(\"LOWERCASE\")\n",
    "    print(doc)\n",
    "    for i in range(doc.shape[0]):\n",
    "        #remove punctuation\n",
    "        doc.set_value(i, re.sub(r'([^\\s\\w])+', '', doc.iloc[i]))\n",
    "    print(\"REMOVE PUNCT\")\n",
    "    print(doc)\n",
    "    for i in range(doc.shape[0]):\n",
    "        #remove stopwords\n",
    "        doc.set_value(i, remove_stopwords(doc.iloc[i]))\n",
    "    print(\"REMOVE STOPWORDS\")\n",
    "    print(doc)\n",
    "    for i in range(doc.shape[0]):\n",
    "        #tokenize\n",
    "        doc.set_value(i, word_tokenize(doc.iloc[i]))\n",
    "    print(\"TOKENIZE\")\n",
    "    print(doc)\n",
    "    for i in range(doc.shape[0]):\n",
    "        #lemmatize\n",
    "        for j in range(len(doc.iloc[i])):\n",
    "            doc.iloc[i][j] = lemmatizer.lemmatize(doc.iloc[i][j])\n",
    "    print(\"LEMMATIZE\")\n",
    "    print(doc)\n",
    "clean(bodies['articleBody'])\n",
    "clean(headlines['Headline'])\n",
    "train_data = pd.merge(bodies, headlines, on='Body ID')\n",
    "\n",
    "#extract tfidf vectors of article body and headline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def default(doc):\n",
    "    return doc\n",
    "\n",
    "def tfidf_extractor(b, h):\n",
    "    vect = TfidfVectorizer(analyzer = 'word', preprocessor = default, tokenizer=default, token_pattern = None)\n",
    "\n",
    "    bodyTFIDF = vect.fit_transform(b)\n",
    "    \n",
    "    #print results\n",
    "    print(\"BODY VOCABULARY\")\n",
    "    print(vect.vocabulary_)\n",
    "    print(\"BODIES\")\n",
    "    print(bodyTFIDF)\n",
    "    \n",
    "    headlineTFIDF = vect.fit_transform(h)\n",
    "    \n",
    "    #print results\n",
    "    print(\"HEADLINE VOCABULARY\")\n",
    "    print(vect.vocabulary_)\n",
    "    print(\"HEADLINES\")\n",
    "    print(headlineTFIDF)\n",
    "    \n",
    "#main action!\n",
    "tfidf_extractor(train_data['articleBody'], train_data['Headline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run down of what we'll be doing during the rest of the week.\n",
    "\n",
    "1. **Implement** cosine similarity.\n",
    "2. **Train** our Support Vector Machine.\n",
    "3. **Make** predictions.\n",
    "4. **Evaluate** our model.\n",
    "4. **Present** our findings!\n",
    "\n",
    "Let's get started! Open up the Resources document, and peruse the links. This document is for you, so please, please add resources as you see fit. And please work with the people around you. This is a **collaborative**, *research* project.\n",
    "\n",
    "Here we provide the functional framework for the project. Your job is to write code to complete the functions you need. It is up to you to use the framework and to pick and choose what features you would like to use (feature engineering). Feel free to explore LDA, TFIDF, cosine similarity, etc. Explore!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the similarity between each pair of document and headline\n",
    "def cosDistance():\n",
    "    #write code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train SVM classifier\n",
    "def svmClass():\n",
    "    #write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "def predict():\n",
    "    #write code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and clean test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print overall accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the accuracy per category (unrelated, discuss, agree, disagree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Look over the accuracy of each category. Do you notice anything interesting? Can you find an explanation(s) for what you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "What have you learned over the past three weeks?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
